{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":99359,"databundleVersionId":11870477,"sourceType":"competition"},{"sourceId":11664504,"sourceType":"datasetVersion","datasetId":7320528}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_train.csv')\nval = pd.read_csv('/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_val.csv')\n\ntrain.head()","metadata":{"_cell_guid":"fce8adf3-1854-4591-aea0-62c5d8c01c1c","_uuid":"adc69a5a-1828-4c2d-bb24-111d38d7ad4c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:53:03.317897Z","iopub.execute_input":"2025-05-05T19:53:03.318134Z","iopub.status.idle":"2025-05-05T19:53:03.788539Z","shell.execute_reply.started":"2025-05-05T19:53:03.318116Z","shell.execute_reply":"2025-05-05T19:53:03.787841Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"       filename timestamp  latitude  longitude  angle  Region_ID\n0  img_0000.jpg     15:03    219698     144782    133          2\n1  img_0001.jpg     15:05    219844     144621    312          2\n2  img_0002.jpg     15:05    219844     144621    359          2\n3  img_0003.jpg     17:11    219514     145016    131          2\n4  img_0004.jpg     17:00    220182     144211     45          2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>timestamp</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>angle</th>\n      <th>Region_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_0000.jpg</td>\n      <td>15:03</td>\n      <td>219698</td>\n      <td>144782</td>\n      <td>133</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_0001.jpg</td>\n      <td>15:05</td>\n      <td>219844</td>\n      <td>144621</td>\n      <td>312</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_0002.jpg</td>\n      <td>15:05</td>\n      <td>219844</td>\n      <td>144621</td>\n      <td>359</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_0003.jpg</td>\n      <td>17:11</td>\n      <td>219514</td>\n      <td>145016</td>\n      <td>131</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_0004.jpg</td>\n      <td>17:00</td>\n      <td>220182</td>\n      <td>144211</td>\n      <td>45</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\n\nfrom tqdm.auto import tqdm\n\nos.makedirs('dataset', exist_ok=True)\nos.makedirs('dataset/train', exist_ok=True)\nos.makedirs('dataset/val', exist_ok=True)\n\ntrain_path = '/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/images_train/images_train'\nval_path = '/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/images_val/images_val'\n\nfor i, row in tqdm(train.iterrows(), total=train.shape[0]):\n    id_ = row['Region_ID']\n    os.makedirs(f'dataset/train/{id_}', exist_ok=True)\n    shutil.copyfile(f'{train_path}/{row[\"filename\"]}', f'dataset/train/{id_}/{row[\"filename\"]}')\n\nfor i, row in tqdm(val.iterrows(), total=val.shape[0]):\n    id_ = row['Region_ID']\n    os.makedirs(f'dataset/val/{id_}', exist_ok=True)\n    shutil.copyfile(f'{val_path}/{row[\"filename\"]}', f'dataset/val/{id_}/{row[\"filename\"]}')","metadata":{"_cell_guid":"5c8e191b-3f62-4157-9eee-14d8db334f2b","_uuid":"3769154a-8275-4e6a-b52f-3c982509dbdb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:53:03.790019Z","iopub.execute_input":"2025-05-05T19:53:03.790298Z","iopub.status.idle":"2025-05-05T19:53:45.695166Z","shell.execute_reply.started":"2025-05-05T19:53:03.790274Z","shell.execute_reply":"2025-05-05T19:53:45.694395Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5811ce3ad324e38ad82c3154f6d0995"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/369 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9fe32fff12742bd8ed4c6eeb0ca0268"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip install datasets transformers accelerate","metadata":{"_cell_guid":"0d2ccda7-0600-4b17-a8d4-fda9f03517d8","_uuid":"3165af2d-0a09-4b3a-83cc-6524b225d9c1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:53:45.695785Z","iopub.execute_input":"2025-05-05T19:53:45.696006Z","iopub.status.idle":"2025-05-05T19:55:13.670670Z","shell.execute_reply.started":"2025-05-05T19:53:45.695989Z","shell.execute_reply":"2025-05-05T19:55:13.669838Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"dataset\")","metadata":{"_cell_guid":"08ef7578-120b-4625-b884-a72a01449bb7","_uuid":"58c513b8-35cf-4930-91eb-7be8f8e48a9d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:13.671673Z","iopub.execute_input":"2025-05-05T19:55:13.671931Z","iopub.status.idle":"2025-05-05T19:55:21.774916Z","shell.execute_reply.started":"2025-05-05T19:55:13.671908Z","shell.execute_reply":"2025-05-05T19:55:21.774148Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/6542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a21c170493da4d99b7285402238f819f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/369 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d700c60ef4524ae7b1a29653ea0ef303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/6542 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f38b391b7ed24d3d85ab77352b4bd95b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/369 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b39f9c81fc9841ef8d048386116d05bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20309d81b9684cf696a370ec33103ab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8b598656364bdd9aa157dddcde25ed"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"labels = ds[\"train\"].features[\"label\"].names\nlabel2id, id2label = dict(), dict()\nfor i, label in enumerate(labels):\n    label2id[label] = i\n    id2label[i] = label","metadata":{"_cell_guid":"055d0b66-cdd0-4916-ad77-e1bb0ceb69a7","_uuid":"ad2dc6c6-7292-498f-89a2-a54fee95189c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:21.776927Z","iopub.execute_input":"2025-05-05T19:55:21.777146Z","iopub.status.idle":"2025-05-05T19:55:21.780980Z","shell.execute_reply.started":"2025-05-05T19:55:21.777129Z","shell.execute_reply":"2025-05-05T19:55:21.780359Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"ds['train'][0]","metadata":{"_cell_guid":"693d0338-0d5e-493b-8206-9a5b0555678e","_uuid":"cbe8a689-76ca-4c6b-8071-faf257891d6b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:21.781553Z","iopub.execute_input":"2025-05-05T19:55:21.781780Z","iopub.status.idle":"2025-05-05T19:55:22.345439Z","shell.execute_reply.started":"2025-05-05T19:55:21.781761Z","shell.execute_reply":"2025-05-05T19:55:22.344852Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256>,\n 'label': 0}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from transformers import ViTFeatureExtractor, AutoImageProcessor\n\nmodel_name_or_path = 'facebook/convnext-large-224-22k-1k'\nfeature_extractor = AutoImageProcessor.from_pretrained(model_name_or_path)","metadata":{"_cell_guid":"aafd479c-3b80-4942-ba10-86012a7d9bf0","_uuid":"3538a809-bf6e-42e7-b887-79f8bdbfc02a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:22.346061Z","iopub.execute_input":"2025-05-05T19:55:22.346270Z","iopub.status.idle":"2025-05-05T19:55:43.387423Z","shell.execute_reply.started":"2025-05-05T19:55:22.346254Z","shell.execute_reply":"2025-05-05T19:55:43.386691Z"}},"outputs":[{"name":"stderr","text":"2025-05-05 19:55:30.927028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746474931.121549      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746474931.175000      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7150c96084c48c399bde0c74f380bbc"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"feature_extractor","metadata":{"_cell_guid":"e3886e71-20f6-4d7f-b79e-c9ae25ee8d6c","_uuid":"3daa4047-b0c2-4c17-8873-0b381f1045ab","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:43.388227Z","iopub.execute_input":"2025-05-05T19:55:43.389130Z","iopub.status.idle":"2025-05-05T19:55:43.393820Z","shell.execute_reply.started":"2025-05-05T19:55:43.389105Z","shell.execute_reply":"2025-05-05T19:55:43.393211Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"ConvNextImageProcessor {\n  \"crop_pct\": 0.875,\n  \"do_normalize\": true,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.485,\n    0.456,\n    0.406\n  ],\n  \"image_processor_type\": \"ConvNextImageProcessor\",\n  \"image_std\": [\n    0.229,\n    0.224,\n    0.225\n  ],\n  \"resample\": 3,\n  \"rescale_factor\": 0.00392156862745098,\n  \"size\": {\n    \"shortest_edge\": 224\n  }\n}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from torchvision import transforms\nfrom torchvision.transforms import (\n    Compose,\n    Resize,\n    RandomHorizontalFlip,\n    ToTensor,\n    Normalize,\n    ColorJitter,\n    RandomApply,\n    GaussianBlur,\n    RandomGrayscale,\n)\n\n# Assuming `feature_extractor` is from a pretrained model (e.g., ViT, ResNet)\nnormalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n\n# Training transforms: Augmentations + normalization\ntrain_transforms = Compose(\n    [\n        Resize(224),  # Spatial dimensions first\n        RandomHorizontalFlip(p=0.5),  # Only if flipping doesn't harm geolocation (e.g., symmetric scenes)\n        RandomApply(\n            [ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)],\n            p=0.5,  # Moderate color jitter, 50% chance\n        ),\n        RandomApply(\n            [GaussianBlur(kernel_size=3)],\n            p=0.2,  # Mild blur, 20% chance\n        ),\n        RandomGrayscale(p=0.1),  # Rare grayscale (10% chance)\n        ToTensor(),\n        normalize,  # Normalize last\n    ]\n)\n\n# Validation transforms: No augmentations, just resize + normalize\nval_transforms = Compose(\n    [\n        Resize(224),\n        ToTensor(),\n        normalize,\n    ]\n)\n\ndef preprocess_train(example_batch):\n    \"\"\"Apply train_transforms across a batch.\"\"\"\n    example_batch[\"pixel_values\"] = [\n        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n    ]\n    return example_batch\n\ndef preprocess_val(example_batch):\n    \"\"\"Apply val_transforms across a batch.\"\"\"\n    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n    return example_batch","metadata":{"_cell_guid":"db40e926-3f43-4c5d-ab2f-827ab33f132d","_uuid":"3eb527eb-f1f3-4abb-82e5-74eeef61d7c2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:43.394623Z","iopub.execute_input":"2025-05-05T19:55:43.394820Z","iopub.status.idle":"2025-05-05T19:55:43.413060Z","shell.execute_reply.started":"2025-05-05T19:55:43.394784Z","shell.execute_reply":"2025-05-05T19:55:43.412367Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# split up training into training + validation\ntrain_ds = ds['train']\nval_ds = ds['validation']","metadata":{"_cell_guid":"aa63b9a9-e5d5-4ece-aff0-9a197d060823","_uuid":"aba9665a-bc97-4079-a720-b5ed81e70017","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:43.413971Z","iopub.execute_input":"2025-05-05T19:55:43.414135Z","iopub.status.idle":"2025-05-05T19:55:43.433757Z","shell.execute_reply.started":"2025-05-05T19:55:43.414123Z","shell.execute_reply":"2025-05-05T19:55:43.433095Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_ds[0]","metadata":{"_cell_guid":"c53ae36a-bc56-4cfd-ac59-f7e8de7ed581","_uuid":"670afcf3-2556-4d29-80f5-20934c8c36a6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:43.434402Z","iopub.execute_input":"2025-05-05T19:55:43.434586Z","iopub.status.idle":"2025-05-05T19:55:43.449810Z","shell.execute_reply.started":"2025-05-05T19:55:43.434573Z","shell.execute_reply":"2025-05-05T19:55:43.449276Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256>,\n 'label': 0}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"train_ds.set_transform(preprocess_train)\nval_ds.set_transform(preprocess_val)","metadata":{"_cell_guid":"f4d635fd-22a7-4d40-a766-1cf1d319745c","_uuid":"1a03a16f-47c8-4fb4-b49d-33cb05e4486d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:43.450521Z","iopub.execute_input":"2025-05-05T19:55:43.450754Z","iopub.status.idle":"2025-05-05T19:55:43.468686Z","shell.execute_reply.started":"2025-05-05T19:55:43.450739Z","shell.execute_reply":"2025-05-05T19:55:43.467972Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import ViTForImageClassification, AutoModelForImageClassification\nmodel_name_or_path = 'facebook/convnext-large-224-22k-1k'\nmodel = AutoModelForImageClassification.from_pretrained(\n    model_name_or_path,\n    num_labels=len(labels),\n    id2label={str(i): c for i, c in enumerate(labels)},\n    label2id={c: str(i) for i, c in enumerate(labels)},\n    ignore_mismatched_sizes=True\n)","metadata":{"_cell_guid":"800bec20-c737-43d5-857c-45c8d95c21a3","_uuid":"b60e7e66-4838-43c9-a855-8525ae49137e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:43.469452Z","iopub.execute_input":"2025-05-05T19:55:43.469674Z","iopub.status.idle":"2025-05-05T19:55:52.227561Z","shell.execute_reply.started":"2025-05-05T19:55:43.469652Z","shell.execute_reply":"2025-05-05T19:55:52.226836Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1a6875301104de88963667d93c7b526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/791M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22252edd82ba4eac81a81c67391bfc90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/791M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"405cb57290bb4e96a6987f75d6d6007f"}},"metadata":{}},{"name":"stderr","text":"Some weights of ConvNextForImageClassification were not initialized from the model checkpoint at facebook/convnext-large-224-22k-1k and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([1000, 1536]) in the checkpoint and torch.Size([15, 1536]) in the model instantiated\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([15]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install wandb","metadata":{"_cell_guid":"8886fd8e-735b-4a70-bc44-ddd4610b75e3","_uuid":"e3784286-b1ee-46e1-872d-163663c8dbde","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:52.231333Z","iopub.execute_input":"2025-05-05T19:55:52.231761Z","iopub.status.idle":"2025-05-05T19:55:55.617659Z","shell.execute_reply.started":"2025-05-05T19:55:52.231742Z","shell.execute_reply":"2025-05-05T19:55:55.616749Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n  'region-id-pred-noCrops-convnext',\n  per_device_train_batch_size=16,\n  num_train_epochs=3,\n  fp16=True,\n  save_steps=100,\n  eval_steps=100,\n  logging_steps=10,\n  learning_rate=2e-4,\n  save_total_limit=2,\n  lr_scheduler_type='cosine',  \n  remove_unused_columns=False,\n  report_to='wandb',\n)","metadata":{"_cell_guid":"e2afcc2c-a1fa-48f5-b710-9d5cab238772","_uuid":"2b27103a-2ae0-4cee-9788-e1091a445ecf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:55.618695Z","iopub.execute_input":"2025-05-05T19:55:55.618946Z","iopub.status.idle":"2025-05-05T19:55:55.691054Z","shell.execute_reply.started":"2025-05-05T19:55:55.618923Z","shell.execute_reply":"2025-05-05T19:55:55.690518Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"!pip install evaluate","metadata":{"_cell_guid":"8bb0c8ca-13c2-43e7-8d77-58b8f3208977","_uuid":"ee5a2e56-1b06-4588-93e0-a34ecda10b53","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:55.691810Z","iopub.execute_input":"2025-05-05T19:55:55.692552Z","iopub.status.idle":"2025-05-05T19:55:59.227548Z","shell.execute_reply.started":"2025-05-05T19:55:55.692533Z","shell.execute_reply":"2025-05-05T19:55:59.226775Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from evaluate import load\n\nmetric = load('accuracy')","metadata":{"_cell_guid":"a50d7fe2-d3b4-4b01-812d-a817bc32e402","_uuid":"0046f539-e052-43a9-828b-c259a10b0b48","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:55:59.228547Z","iopub.execute_input":"2025-05-05T19:55:59.228816Z","iopub.status.idle":"2025-05-05T19:56:00.086639Z","shell.execute_reply.started":"2025-05-05T19:55:59.228773Z","shell.execute_reply":"2025-05-05T19:56:00.085951Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54496d7718ce44a085b688085f4ec0a3"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import numpy as np\n\n# the compute_metrics function takes a Named Tuple as input:\n# predictions, which are the logits of the model as Numpy arrays,\n# and label_ids, which are the ground-truth labels as Numpy arrays.\ndef compute_metrics(eval_pred):\n    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    return metric.compute(predictions=predictions, references=eval_pred.label_ids)","metadata":{"_cell_guid":"6f9baceb-7e0f-43c3-9905-afcc647f007b","_uuid":"13cf6e03-43f2-4242-a06c-eae4e0dc16d8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:56:00.087429Z","iopub.execute_input":"2025-05-05T19:56:00.087805Z","iopub.status.idle":"2025-05-05T19:56:00.091830Z","shell.execute_reply.started":"2025-05-05T19:56:00.087763Z","shell.execute_reply":"2025-05-05T19:56:00.091086Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch\n\ndef collate_fn(batch):\n    return {\n        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n        'labels': torch.tensor([x['label'] for x in batch])\n    }","metadata":{"_cell_guid":"6390f3f7-851b-4dce-b5b4-4c6875ee81b3","_uuid":"3fae6238-044b-4bd2-9073-d56f747540ed","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:56:00.092648Z","iopub.execute_input":"2025-05-05T19:56:00.092903Z","iopub.status.idle":"2025-05-05T19:56:00.108131Z","shell.execute_reply.started":"2025-05-05T19:56:00.092881Z","shell.execute_reply":"2025-05-05T19:56:00.107533Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from transformers import Trainer\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    tokenizer=feature_extractor,\n    compute_metrics=compute_metrics,\n    data_collator=collate_fn,\n)","metadata":{"_cell_guid":"8c5fad0f-887c-4684-a2fc-2d5711010263","_uuid":"0cf29462-02c4-4c0d-bd06-94bf8c1abe7a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:56:00.108995Z","iopub.execute_input":"2025-05-05T19:56:00.109222Z","iopub.status.idle":"2025-05-05T19:56:02.067990Z","shell.execute_reply.started":"2025-05-05T19:56:00.109207Z","shell.execute_reply":"2025-05-05T19:56:02.067186Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/963735583.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import wandb\n\nwandb.login(key='5d0f53cfd15364d3cce1d5e9ca6f631fd831a669')","metadata":{"_cell_guid":"3649a6b2-cafa-4b7a-b25d-d001b24cff58","_uuid":"b34ac839-4918-4ed5-9467-41fe81ce5207","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:56:02.068887Z","iopub.execute_input":"2025-05-05T19:56:02.069156Z","iopub.status.idle":"2025-05-05T19:56:08.070464Z","shell.execute_reply.started":"2025-05-05T19:56:02.069132Z","shell.execute_reply":"2025-05-05T19:56:08.069976Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshanh042-310\u001b[0m (\u001b[33mshanh042-310-iiit-hyderabad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"_cell_guid":"9b966790-b5f6-4aec-a901-a1db2b90333d","_uuid":"13f0b5ac-2414-4bbb-bef6-ddc88349b1ff","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:56:08.071233Z","iopub.execute_input":"2025-05-05T19:56:08.071991Z","iopub.status.idle":"2025-05-05T19:56:08.075520Z","shell.execute_reply.started":"2025-05-05T19:56:08.071971Z","shell.execute_reply":"2025-05-05T19:56:08.074840Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"train_results = trainer.train()\n# rest is optional but nice to have\ntrainer.save_model()\ntrainer.log_metrics(\"train\", train_results.metrics)\ntrainer.save_metrics(\"train\", train_results.metrics)\ntrainer.save_state()\n\neval_results = trainer.evaluate()\n\ntrainer.log_metrics('eval', eval_results)\ntrainer.save_metrics('eval', eval_results)","metadata":{"_cell_guid":"feccbef5-b272-4eb4-a9c6-c0bd18654704","_uuid":"a2342127-05ba-478e-a510-6c909921238a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:56:08.076435Z","iopub.execute_input":"2025-05-05T19:56:08.076688Z","iopub.status.idle":"2025-05-05T20:15:23.760913Z","shell.execute_reply.started":"2025-05-05T19:56:08.076669Z","shell.execute_reply":"2025-05-05T20:15:23.760330Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250505_195611-bltj16a5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shanh042-310-iiit-hyderabad/huggingface/runs/bltj16a5' target=\"_blank\">region-id-pred-noCrops-convnext</a></strong> to <a href='https://wandb.ai/shanh042-310-iiit-hyderabad/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shanh042-310-iiit-hyderabad/huggingface' target=\"_blank\">https://wandb.ai/shanh042-310-iiit-hyderabad/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shanh042-310-iiit-hyderabad/huggingface/runs/bltj16a5' target=\"_blank\">https://wandb.ai/shanh042-310-iiit-hyderabad/huggingface/runs/bltj16a5</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1227' max='1227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1227/1227 18:52, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.886500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.364200</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.959500</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.832000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.602600</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.579200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.429300</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.256300</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.419900</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.155200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.202100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.245200</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.022500</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.056100</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.039200</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.979600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.070700</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.882200</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.824700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.696200</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.810800</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.771300</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.727600</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.851300</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.858300</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.808400</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.730100</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.648900</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.609700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.550700</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.670500</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.767800</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.732300</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.538300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.522300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.445100</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.738100</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.610400</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.626500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.533500</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.588400</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.273700</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.341500</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.244600</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.398900</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.397500</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.296000</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.310000</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.299200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.185900</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.189100</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.137900</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.244000</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.219100</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.222500</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.412100</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.257900</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.194400</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.171900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.242200</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.126600</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.272200</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.125400</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.268800</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.155300</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.268200</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.150300</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.155800</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.109100</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.172100</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.149700</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.133500</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.092700</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.212600</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.285600</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.115200</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.111400</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.140100</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.122800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.193700</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.219300</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.148500</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.055200</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.023800</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.017800</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.035900</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.021700</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.025200</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.042100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.037800</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.057500</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.056900</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.028200</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.031600</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.025300</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.064800</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.009600</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.054100</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.025400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.031500</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.006700</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.040400</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.018700</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.021900</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.018100</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.033400</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.036100</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.021700</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.037900</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.014600</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.010900</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.006100</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.011400</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.029200</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.010900</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.016800</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.036300</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.016000</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.008200</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.029800</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.033600</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.013600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"***** train metrics *****\n  epoch                    =          3.0\n  total_flos               = 3239795783GF\n  train_loss               =       0.4201\n  train_runtime            =   0:19:01.34\n  train_samples_per_second =       17.195\n  train_steps_per_second   =        1.075\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [47/47 00:08]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =        3.0\n  eval_accuracy           =     0.9404\n  eval_loss               =     0.2179\n  eval_runtime            = 0:00:08.47\n  eval_samples_per_second =     43.562\n  eval_steps_per_second   =      5.549\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!zip -r arc.zip region-id-pred/","metadata":{"_cell_guid":"8073c67d-89cc-4929-be0e-ecc3f94de573","_uuid":"eb1c28c2-b8a6-43a9-bd98-1eaee4b2f379","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:23.761625Z","iopub.execute_input":"2025-05-05T20:15:23.761886Z","iopub.status.idle":"2025-05-05T20:15:23.964890Z","shell.execute_reply.started":"2025-05-05T20:15:23.761862Z","shell.execute_reply":"2025-05-05T20:15:23.963513Z"}},"outputs":[{"name":"stdout","text":"\tzip warning: name not matched: region-id-pred/\n\nzip error: Nothing to do! (try: zip -r arc.zip . -i region-id-pred/)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline('image-classification', 'region-id-pred-noCrops-convnext/checkpoint-1227')","metadata":{"_cell_guid":"e4e28b54-9b9c-440e-a3f4-e3c73d3af594","_uuid":"1a490508-6f37-4d0d-abe1-3bd0dd4d3090","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:23.966745Z","iopub.execute_input":"2025-05-05T20:15:23.967111Z","iopub.status.idle":"2025-05-05T20:15:25.575990Z","shell.execute_reply.started":"2025-05-05T20:15:23.967079Z","shell.execute_reply":"2025-05-05T20:15:25.575204Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# pipe('/kaggle/working/dataset/train/1/img_0510.jpg')","metadata":{"_cell_guid":"c24e36fd-4c1e-4217-a4ed-5989f71b1cef","_uuid":"d4917caf-2eae-4589-bf80-884944285f70","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:25.576837Z","iopub.execute_input":"2025-05-05T20:15:25.577098Z","iopub.status.idle":"2025-05-05T20:15:27.550984Z","shell.execute_reply.started":"2025-05-05T20:15:25.577075Z","shell.execute_reply":"2025-05-05T20:15:27.550069Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:27.551850Z","iopub.execute_input":"2025-05-05T20:15:27.552527Z","iopub.status.idle":"2025-05-05T20:15:27.566332Z","shell.execute_reply.started":"2025-05-05T20:15:27.552504Z","shell.execute_reply":"2025-05-05T20:15:27.565810Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"train_dir = '/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/images_train/images_train'\nval_dir = '/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/images_val/images_val'","metadata":{"_cell_guid":"1d01bf34-a50b-46c5-a38a-546fb3440bc4","_uuid":"46a57d55-85d5-4ab7-89a4-9d7194f2beb7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:27.567219Z","iopub.execute_input":"2025-05-05T20:15:27.567448Z","iopub.status.idle":"2025-05-05T20:15:27.580738Z","shell.execute_reply.started":"2025-05-05T20:15:27.567430Z","shell.execute_reply":"2025-05-05T20:15:27.580231Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def predict(x, dir_):\n    preds = pipe(f'{dir_}/{x}')\n    preds_sorted = sorted(preds, key=lambda x: x['score'], reverse=True)\n    return preds_sorted[0]['label']","metadata":{"_cell_guid":"fb5dc3f9-ea01-49d2-a5ec-9e3c461e76a9","_uuid":"88e8d004-ef98-423e-baf2-07bddfb07bcf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:27.581517Z","iopub.execute_input":"2025-05-05T20:15:27.581773Z","iopub.status.idle":"2025-05-05T20:15:27.594312Z","shell.execute_reply.started":"2025-05-05T20:15:27.581755Z","shell.execute_reply":"2025-05-05T20:15:27.593830Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"train_new = pd.read_csv('/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_train.csv')\nval_new = pd.read_csv('/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_val.csv')\n\n# train_new['pred'] = train_new['filename'].apply(lambda x: predict(x, dir_=train_dir))\nval_new['pred'] = val_new['filename'].apply(lambda x: predict(x, dir_=val_dir))","metadata":{"_cell_guid":"690e970a-1db5-481c-abec-a3308b34c37d","_uuid":"f70abea6-1d44-4ff6-9e99-69c0cf128210","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:27.594926Z","iopub.execute_input":"2025-05-05T20:15:27.595106Z","iopub.status.idle":"2025-05-05T20:15:39.539302Z","shell.execute_reply.started":"2025-05-05T20:15:27.595093Z","shell.execute_reply":"2025-05-05T20:15:39.538730Z"}},"outputs":[{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"metric.compute(predictions=val_new['pred'], references=val_new['Region_ID'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:31:57.340894Z","iopub.execute_input":"2025-05-05T20:31:57.341634Z","iopub.status.idle":"2025-05-05T20:31:57.357470Z","shell.execute_reply.started":"2025-05-05T20:31:57.341607Z","shell.execute_reply":"2025-05-05T20:31:57.356958Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.924119241192412}"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"train_new.to_csv('train_noCrops_convnext.csv', index=False)","metadata":{"_cell_guid":"73342743-32bf-47b7-ad09-1e8cd696c2dd","_uuid":"989a854e-c860-4784-a92b-0f54f96db906","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:39.539984Z","iopub.execute_input":"2025-05-05T20:15:39.540174Z","iopub.status.idle":"2025-05-05T20:15:39.563292Z","shell.execute_reply.started":"2025-05-05T20:15:39.540160Z","shell.execute_reply":"2025-05-05T20:15:39.562822Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"val_new.to_csv('val_noCrops_convnext.csv', index=False)","metadata":{"_cell_guid":"e6885d1d-e7f5-457a-baff-3aba2bad7633","_uuid":"c2114604-ac10-42e9-8277-49b084c6d66f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:39.563976Z","iopub.execute_input":"2025-05-05T20:15:39.564174Z","iopub.status.idle":"2025-05-05T20:15:39.569927Z","shell.execute_reply.started":"2025-05-05T20:15:39.564159Z","shell.execute_reply":"2025-05-05T20:15:39.569367Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin('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')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:39.570692Z","iopub.execute_input":"2025-05-05T20:15:39.570945Z","iopub.status.idle":"2025-05-05T20:15:39.912408Z","shell.execute_reply.started":"2025-05-05T20:15:39.570922Z","shell.execute_reply":"2025-05-05T20:15:39.911650Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"out_df = pd.DataFrame({\n    'id': range(len(val_new['pred'])),\n    'Region_ID': list(val_new['pred'])\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:39.913200Z","iopub.execute_input":"2025-05-05T20:15:39.913400Z","iopub.status.idle":"2025-05-05T20:15:39.919076Z","shell.execute_reply.started":"2025-05-05T20:15:39.913384Z","shell.execute_reply":"2025-05-05T20:15:39.918418Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"test_path = '/kaggle/input/smai-test/images_test'\nfrom tqdm.auto import tqdm\nimport os\n\ni = len(val_new['pred'])\nids = []\npreds = []\nfor file in tqdm(sorted(os.listdir(test_path))):\n    pred = predict(file, dir_=test_path)\n    ids.append(i)\n    preds.append(pred)\n    i += 1\n\ntest_df = pd.DataFrame({\n    'id': ids,\n    'Region_ID': preds\n})\n\nout_df = pd.concat([out_df, test_df], axis=0)\nout_df.to_csv('2022114008_3.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:15:39.919887Z","iopub.execute_input":"2025-05-05T20:15:39.920087Z","iopub.status.idle":"2025-05-05T20:15:54.347152Z","shell.execute_reply.started":"2025-05-05T20:15:39.920072Z","shell.execute_reply":"2025-05-05T20:15:54.346449Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/369 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b584cdb23c70491d8257d11e5cab176e"}},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"## LatLong","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_train.csv')\nval = pd.read_csv('/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_val.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import DBSCAN\n\n# Assume df is your DataFrame with 'latitude' and 'longitude' columns\n# Step 1: IQR Filtering\ndef iqr_filter(df, columns):\n    Q1 = df[columns].quantile(0.25)\n    Q3 = df[columns].quantile(0.75)\n    IQR = Q3 - Q1\n    mask = ~((df[columns] < (Q1 - 1.5 * IQR)) | (df[columns] > (Q3 + 1.5 * IQR))).any(axis=1)\n    return df[mask]\n\n# Step 2: DBSCAN Filtering\ndef dbscan_filter(df, eps=300, min_samples=20):\n    coords = df[['latitude', 'longitude']].to_numpy()\n    db = DBSCAN(eps=eps, min_samples=min_samples).fit(coords)\n    mask = db.labels_ != -1\n    return df[mask]\n\n# Apply filters\ntrain = iqr_filter(train, ['latitude', 'longitude'])\ntrain = dbscan_filter(train, eps=300, min_samples=20)\n\n# Plot result\nplt.scatter(train['latitude'], train['longitude'], c=train['Region_ID'])\nplt.xlabel(\"Latitude\")\nplt.ylabel(\"Longitude\")\nplt.title(\"Scatter Plot after IQR + DBSCAN Filtering\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val = val.drop(index=[95, 145, 146, 158, 159, 160, 161])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nfeatures_to_scale = ['latitude', 'longitude']\ntrain[features_to_scale] = sc.fit_transform(train[features_to_scale])\nval[features_to_scale] = sc.transform(val[features_to_scale])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\nimport torchvision\nfrom torchvision.transforms import (\n    Compose,\n    Resize,\n    RandomHorizontalFlip,\n    ToTensor,\n    Normalize,\n    ColorJitter,\n    RandomApply,\n    GaussianBlur,\n    RandomGrayscale,\n)\n\ndef get_transforms(train=False):\n    if train:\n        return transforms.Compose([\n            transforms.Resize(256),\n            transforms.RandomCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\ntrain_transforms = get_transforms(True)\nval_transforms = get_transforms()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nfrom sklearn.preprocessing import OneHotEncoder\nimport pickle\n\n# ====================== Step 1: Fit Encoder on Train Data ======================\n'''\ntrain_df = train.copy()\nencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nencoder.fit(train_df[\"Region_ID\"].values.reshape(-1, 1))\n\n# Save the encoder for reuse\nwith open(\"region_encoder.pkl\", \"wb\") as f:\n    pickle.dump(encoder, f)\n'''\n\n# ====================== Dataset Class with Consistent Encoding ======================\nclass GeoLocationDataset(Dataset):\n    def __init__(self, df, image_dir, encoder_path=\"region_encoder.pkl\", transform=None):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): DataFrame with columns: [filename, latitude, longitude, Region_ID].\n            image_dir (str): Path to images.\n            encoder_path (str): Path to pre-fitted OneHotEncoder.\n            transform (callable, optional): Image transforms.\n        \"\"\"\n        self.df = df\n        self.image_dir = image_dir\n        self.transform = transform\n        \n        # Load pre-fitted encoder\n        with open(encoder_path, \"rb\") as f:\n            self.encoder = pickle.load(f)\n        \n        # One-hot encode Region_ID\n        self.region_ids = self.encoder.transform(\n            self.df[\"Region_ID\"].values.reshape(-1, 1)\n        )\n        \n        # Targets (latitude, longitude)\n        self.targets = torch.tensor(\n            self.df[[\"latitude\", \"longitude\"]].values, dtype=torch.float32\n        )\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        # Load image\n        img_name = os.path.join(self.image_dir, self.df.iloc[idx, 0])  # Assuming filename is in column 0\n        image = Image.open(img_name).convert(\"RGB\")\n        \n        # Apply transforms\n        if self.transform:\n            image = self.transform(image)\n            \n        # Get one-hot encoded Region_ID and targets\n        region_id = torch.tensor(self.region_ids[idx], dtype=torch.float32)\n        target = self.targets[idx]\n        \n        return image, region_id, target\n\n# ====================== Example Usage ======================\nif True:\n    from torchvision import transforms\n\n    # Load datasets with consistent encoding\n    train_dir='/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/images_train/images_train'\n    val_dir='/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/images_val/images_val'\n    train_dataset = GeoLocationDataset(train, train_dir, transform=train_transforms)\n    val_dataset = GeoLocationDataset(val, val_dir, transform=val_transforms)\n\n    # Verify consistency\n    print(f\"Train Region IDs: {train_dataset.encoder.categories_}\")\n    print(f\"Val Region IDs: {val_dataset.encoder.categories_}\")  # Should match train's","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:51:38.789671Z","iopub.execute_input":"2025-05-05T21:51:38.789940Z","iopub.status.idle":"2025-05-05T21:51:38.829537Z","shell.execute_reply.started":"2025-05-05T21:51:38.789921Z","shell.execute_reply":"2025-05-05T21:51:38.828797Z"}},"outputs":[{"name":"stdout","text":"Train Region IDs: [array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])]\nVal Region IDs: [array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"len(val_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:51:41.740884Z","iopub.execute_input":"2025-05-05T21:51:41.741560Z","iopub.status.idle":"2025-05-05T21:51:41.745913Z","shell.execute_reply.started":"2025-05-05T21:51:41.741538Z","shell.execute_reply":"2025-05-05T21:51:41.745267Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"362"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:51:52.110259Z","iopub.execute_input":"2025-05-05T21:51:52.110807Z","iopub.status.idle":"2025-05-05T21:51:52.115001Z","shell.execute_reply.started":"2025-05-05T21:51:52.110785Z","shell.execute_reply":"2025-05-05T21:51:52.114267Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:28:43.857421Z","iopub.execute_input":"2025-05-05T21:28:43.857734Z","iopub.status.idle":"2025-05-05T21:28:43.862573Z","shell.execute_reply.started":"2025-05-05T21:28:43.857713Z","shell.execute_reply":"2025-05-05T21:28:43.862019Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"from transformers import AutoModelForImageClassification\n\nbackbone = AutoModelForImageClassification.from_pretrained('facebook/convnext-large-224-22k-1k')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:52:12.364003Z","iopub.execute_input":"2025-05-05T21:52:12.364277Z","iopub.status.idle":"2025-05-05T21:52:36.103277Z","shell.execute_reply.started":"2025-05-05T21:52:12.364257Z","shell.execute_reply":"2025-05-05T21:52:36.102465Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b3d784b0c75416db1d267fad03e6455"}},"metadata":{}},{"name":"stderr","text":"2025-05-05 21:52:21.612308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746481941.800158      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746481941.855949      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/791M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bed9ba73e3ac4c869f2e56fa51c8ece6"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom PIL import Image\nfrom sklearn.preprocessing import OneHotEncoder\nimport pickle\nimport wandb\nfrom torchvision import transforms\n\n# ====================== Config ======================\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nconfig = {\n    'batch_size': 8,\n    'lr': 3e-4,\n    'epochs': 100,\n    'patience': 5,\n    'image_size': 224\n}\n\n# backbone = backbone.to(device)\n\n# ====================== Model ======================\nclass GeoModel(nn.Module):\n    def __init__(self, backbone_model, num_regions):\n        super().__init__()\n        self.backbone = backbone_model\n            \n        # Replace classifier\n        self.backbone.classifier = nn.Identity()\n        \n        # Region embedding\n        self.region_proj = nn.Linear(num_regions, 64)\n        \n        # Regression head\n        self.head = nn.Sequential(\n            nn.Linear(1600, 256),\n            nn.GELU(),\n            nn.Linear(256, 2)\n        )\n    \n    def forward(self, x, region):\n        img_features = self.backbone(pixel_values=x).logits\n        region_emb = self.region_proj(region)\n        combined = torch.cat([img_features, region_emb], dim=1)\n        return self.head(combined)\n\n# ====================== Training Loop ======================\ndef train_model():\n    wandb.init(project=\"geo-localization\", config=config)\n    \n    model = GeoModel(backbone, 15).to(device)\n    optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n    scheduler = CosineAnnealingLR(optimizer, T_max=config['epochs'] * len(train_loader))\n    criterion = nn.MSELoss()\n    \n    best_val_loss = float('inf')\n    patience_counter = 0\n    \n    for epoch in range(config['epochs']):\n        # Training\n        model.train()\n        train_loss = 0.0\n        for images, regions, targets in train_loader:\n            images, regions, targets = images.to(device), regions.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images, regions)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            \n            train_loss += loss.item()\n            wandb.log({\"train_batch_loss\": loss.item()})\n        \n        # Validation\n        val_loss = 0.0\n        model.eval()\n        with torch.no_grad():\n            for images, regions, targets in val_loader:\n                images, regions, targets = images.to(device), regions.to(device), targets.to(device)\n                outputs = model(images, regions)\n                val_loss += criterion(outputs, targets).item()\n        \n        avg_train_loss = train_loss / len(train_loader)\n        avg_val_loss = val_loss / len(val_loader)\n        \n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": avg_train_loss,\n            \"val_loss\": avg_val_loss,\n            \"lr\": scheduler.get_last_lr()[0]\n        })\n        \n        print(f\"Epoch {epoch+1}/{config['epochs']} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n        \n        # Early stopping\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), \"best_model.pth\")\n            wandb.save(\"best_model.pth\")\n        else:\n            patience_counter += 1\n            if patience_counter >= config['patience']:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n    \n    # Load best model\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:52:36.104447Z","iopub.execute_input":"2025-05-05T21:52:36.105030Z","iopub.status.idle":"2025-05-05T21:52:36.119033Z","shell.execute_reply.started":"2025-05-05T21:52:36.105010Z","shell.execute_reply":"2025-05-05T21:52:36.118156Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import wandb\n\nwandb.login(key='5d0f53cfd15364d3cce1d5e9ca6f631fd831a669')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:56:44.633872Z","iopub.execute_input":"2025-05-05T21:56:44.634164Z","iopub.status.idle":"2025-05-05T21:56:44.774805Z","shell.execute_reply.started":"2025-05-05T21:56:44.634141Z","shell.execute_reply":"2025-05-05T21:56:44.774152Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshanh042-310\u001b[0m (\u001b[33mshanh042-310-iiit-hyderabad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# geomodel = train_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:56:47.186345Z","iopub.execute_input":"2025-05-05T21:56:47.186673Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250505_215647-3r5dudl2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shanh042-310-iiit-hyderabad/geo-localization/runs/3r5dudl2' target=\"_blank\">imperial-bantha-2</a></strong> to <a href='https://wandb.ai/shanh042-310-iiit-hyderabad/geo-localization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shanh042-310-iiit-hyderabad/geo-localization' target=\"_blank\">https://wandb.ai/shanh042-310-iiit-hyderabad/geo-localization</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shanh042-310-iiit-hyderabad/geo-localization/runs/3r5dudl2' target=\"_blank\">https://wandb.ai/shanh042-310-iiit-hyderabad/geo-localization/runs/3r5dudl2</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/100 | Train Loss: 0.2578 | Val Loss: 0.0780\nEpoch 2/100 | Train Loss: 0.0786 | Val Loss: 0.0609\nEpoch 3/100 | Train Loss: 0.0719 | Val Loss: 0.0638\nEpoch 4/100 | Train Loss: 0.0443 | Val Loss: 0.0478\nEpoch 5/100 | Train Loss: 0.0271 | Val Loss: 0.0353\nEpoch 6/100 | Train Loss: 0.0176 | Val Loss: 0.0323\nEpoch 7/100 | Train Loss: 0.0153 | Val Loss: 0.0320\nEpoch 8/100 | Train Loss: 0.0115 | Val Loss: 0.0307\nEpoch 9/100 | Train Loss: 0.0130 | Val Loss: 0.0326\nEpoch 10/100 | Train Loss: 0.0098 | Val Loss: 0.0272\nEpoch 11/100 | Train Loss: 0.0065 | Val Loss: 0.0276\nEpoch 12/100 | Train Loss: 0.0065 | Val Loss: 0.0396\nEpoch 13/100 | Train Loss: 0.0112 | Val Loss: 0.0361\nEpoch 14/100 | Train Loss: 0.0112 | Val Loss: 0.0258\nEpoch 15/100 | Train Loss: 0.0046 | Val Loss: 0.0257\nEpoch 16/100 | Train Loss: 0.0045 | Val Loss: 0.0244\nEpoch 17/100 | Train Loss: 0.0038 | Val Loss: 0.0260\nEpoch 18/100 | Train Loss: 0.0064 | Val Loss: 0.0458\nEpoch 19/100 | Train Loss: 0.0213 | Val Loss: 0.0273\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model = GeoModel(backbone, 15)\nmodel.load_state_dict(torch.load(\"best_model.pth\"))\n\nmodel = model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ntest = pd.read_csv('/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_val.csv')\n\n# Change Region_ID in test to last 369 values of 2022114008_3.csv\n\nregion_preds = pd.read_csv('2022114008_3.csv').tail(369)\n\ntest['Region_ID'] = region_preds['Region_ID']\n\ntest_dataset = GeoLocationDataset(test, '/kaggle/input/smai-test/images_test', transform=val_transforms)\n\ntest_loader = DataLoader(test_dataset, batch_size=8)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = []\n\nwith torch.no_grad():\n    for images, regions, targets in val_loader:\n        images, regions, targets = images.to(device), regions.to(device), targets.to(device)\n        outputs = model(images, regions)\n        preds.extend(list(outputs.cpu()))\n\n\nwith torch.no_grad():\n    for images, regions, targets in test_loader:\n        images, regions, targets = images.to(device), regions.to(device), targets.to(device)\n        outputs = model(images, regions)\n        preds.extend(list(outputs.cpu()))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}